---
layout: post
title: 'Đặt câu hỏi đúng thời 4 chấm 0. Gemini, chat gpt,... !! [Phần 2] Thấu hiểu "Prompt" - Chìa khóa mở ra sức mạnh AI!'
author: sal
categories: [ Coding 💻 ]
tags: [ tips,tool ]
image: assets/images/2023/lap-trinh/avts/javascript-come-back-avt.webp
lazyimages: "enabled"
isGithubComments: false
excerpt: Hãy tưởng tượng ChatGPT như một "đầu bếp AI" siêu đẳng, có thể giúp bạn hiện thực hóa mọi ý tưởng ẩm thực, dù là phức tạp nhất!
adsense: "enabled"
keywords:
  - Tasker
  - Chia sẻ profile tasker
  - Tối ưu Tasker
  - Tasker là gì?
  - Android Automation
  - Shortcuts android
date: 2024-05-19 10:01:10 +0700
permalink: coding/dat-cau-hoi-dung-thoi-hien-dai-4-0-p3
skip_toc: true
---

> Hoàn toàn đồng ý! Phương pháp cải tiến câu hỏi là một cách đơn giản nhưng hiệu quả để tận dụng tối đa mô hình ngôn ngữ lớn như ChatGPT. Hãy cùng tìm hiểu cách thức hoạt động và những lợi ích mà phương pháp này mang lại.

**Ý tưởng cốt lõi:**

Ý tưởng cơ bản của phương pháp này là khai thác khả năng hiểu sâu về ngôn ngữ và mẫu câu của mô hình ngôn ngữ lớn để cải thiện câu hỏi của chúng ta. Khi chúng ta đặt câu hỏi, mô hình ngôn ngữ lớn có thể suy luận và gợi ý những từ ngữ, mẫu câu hoặc thông tin liên quan có thể giúp câu hỏi trở nên cụ thể, rõ ràng và có ngữ cảnh hơn.

**Cách thức hoạt động:**

1.  **Đặt câu hỏi:** Bạn bắt đầu bằng cách đặt một câu hỏi chung chung hoặc chưa rõ ràng.
2.  **Mô hình cải tiến câu hỏi:** Mô hình ngôn ngữ lớn sẽ phân tích câu hỏi của bạn, dựa vào kiến thức đã được huấn luyện về các mẫu câu, từ ngữ liên quan để đưa ra một phiên bản câu hỏi tốt hơn, chi tiết hơn.
3.  **Xác nhận sử dụng câu hỏi mới:** Mô hình sẽ hỏi bạn có muốn sử dụng câu hỏi mới này hay không. Nếu đồng ý, mô hình sẽ sử dụng câu hỏi đã được cải tiến. Nếu không, mô hình sẽ sử dụng câu hỏi ban đầu của bạn.

**Ví dụ:**

*   **Câu hỏi ban đầu:** "Tôi có nên học tại Đại học Vanderbilt không?"
*   **Câu hỏi được cải tiến:** "Những yếu tố nào tôi nên cân nhắc khi quyết định có nên học tại Đại học Vanderbilt hay không, và chúng phù hợp với mục tiêu và ưu tiên cá nhân của tôi như thế nào?"

**Lợi ích:**

*   **Câu hỏi tốt hơn:** Phương pháp này giúp chúng ta có được những câu hỏi chất lượng hơn, từ đó nhận được câu trả lời chính xác và hữu ích hơn từ mô hình ngôn ngữ lớn.
*   **Tự suy ngẫm:** Việc xem xét câu hỏi đã được cải tiến giúp chúng ta suy ngẫm lại những gì mình thực sự muốn hỏi và có thể bổ sung thêm thông tin để làm rõ câu hỏi.
*   **Xác định thông tin còn thiếu:** Đôi khi, câu hỏi được cải tiến có thể gợi ý cho chúng ta những khía cạnh khác của vấn đề mà chúng ta chưa nghĩ đến, từ đó bổ sung thông tin để có được câu trả lời đầy đủ hơn.

**Cách sử dụng:**

Để sử dụng phương pháp này, bạn chỉ cần thêm vào đoạn prompt (lời nhắc) những câu như:

*   "Từ bây giờ, mỗi khi tôi hỏi, hãy đề xuất một phiên bản câu hỏi tốt hơn."
*   "Từ bây giờ, mỗi khi tôi hỏi, hãy đề xuất một phiên bản câu hỏi tốt hơn và hỏi tôi có muốn sử dụng nó hay không."

Bạn cũng có thể tùy chỉnh lời nhắc để phù hợp với nhu cầu cụ thể của mình, ví dụ như:

*   "Mỗi khi tôi hỏi về chế độ ăn kiêng, hãy đề xuất một phiên bản câu hỏi tập trung vào thói quen ăn uống lành mạnh và dinh dưỡng hợp lý. Hỏi tôi có muốn sử dụng câu hỏi mới cho câu hỏi đầu tiên không."

**Lưu ý:**

Phương pháp cải tiến câu hỏi không đảm bảo luôn mang lại kết quả hoàn hảo, nhưng nó là một công cụ hữu ích để nâng cao chất lượng tương tác của bạn với mô hình ngôn ngữ lớn. Hãy thử áp dụng và trải nghiệm những lợi ích mà nó mang lại!

## Các mẫu

 **Mẫu "Xác minh Nhận thức" (Cognitive Verifier Pattern):**

Mẫu này giúp mô hình ngôn ngữ lớn (LLM) đưa ra câu trả lời chính xác hơn bằng cách tự đặt ra các câu hỏi bổ sung để làm rõ vấn đề trước khi đưa ra câu trả lời cuối cùng.

**Cấu trúc lời nhắc (Prompt):**

Khi được hỏi một câu hỏi, hãy làm theo các quy tắc sau:

1.  Đặt ra một số câu hỏi bổ sung để hiểu rõ hơn về câu hỏi gốc.
2.  Kết hợp các câu trả lời cho từng câu hỏi bổ sung để đưa ra câu trả lời cuối cùng cho câu hỏi gốc.

**Ví dụ:**

*   **Lời nhắc gốc:**

"Khi được hỏi một câu hỏi, hãy làm theo các quy tắc sau: Đặt ra một số câu hỏi bổ sung để hiểu rõ hơn về câu hỏi gốc. Kết hợp các câu trả lời cho từng câu hỏi bổ sung để đưa ra câu trả lời cuối cùng cho câu hỏi gốc."

*   **Lời nhắc tùy chỉnh:**
    *   "Khi được yêu cầu tạo một công thức nấu ăn, hãy làm theo các quy tắc sau: Đặt ra các câu hỏi bổ sung về các nguyên liệu tôi có và dụng cụ nấu ăn tôi sở hữu. Kết hợp các câu trả lời cho các câu hỏi này để đưa ra một công thức mà tôi có thể làm được."
    *   "Khi được yêu cầu lên kế hoạch cho một chuyến đi, hãy làm theo các quy tắc sau: Đặt ra các câu hỏi bổ sung về ngân sách của tôi, các hoạt động ưa thích và việc tôi có xe hơi hay không. Kết hợp các câu trả lời cho các câu hỏi này để lên kế hoạch hành trình tốt hơn."

**Mẫu "Đối tượng Mục tiêu" (Audience Persona Pattern):**

Mẫu này giúp LLM điều chỉnh câu trả lời phù hợp với đối tượng mục tiêu cụ thể.

**Cấu trúc lời nhắc:**

Giải thích X cho tôi. Giả sử tôi là Y.

(Thay "Y" bằng đối tượng mục tiêu cụ thể, ví dụ: "người không có kiến thức về khoa học máy tính" hoặc "chuyên gia chăm sóc sức khỏe".)

**Ví dụ:**

*   "Giải thích về các mô hình ngôn ngữ lớn cho tôi. Giả sử tôi là một con chim."
*   "Giải thích cách chuỗi cung ứng cho các cửa hàng tạp hóa ở Mỹ hoạt động cho tôi. Giả sử tôi là Thành Cát Tư Hãn."

**Mẫu "Tương tác Đảo ngược" (Flipped Interaction Pattern):**

Mẫu này cho phép LLM đặt câu hỏi cho người dùng để thu thập thông tin cần thiết trước khi đưa ra câu trả lời hoặc giải pháp.

**Cấu trúc lời nhắc:**

Tôi muốn bạn đặt câu hỏi cho tôi để đạt được X.

Bạn nên đặt câu hỏi cho đến khi điều kiện Y được đáp ứng hoặc để đạt được mục tiêu này (hoặc mãi mãi).

(Tùy chọn) hỏi tôi từng câu một, hai câu một lúc, hỏi tôi câu hỏi đầu tiên, v.v.

(Thay "X" bằng mục tiêu cụ thể, ví dụ: "tạo một kế hoạch bữa ăn" hoặc "tạo các biến thể cho tài liệu tiếp thị của tôi." Chỉ định khi nào nên ngừng đặt câu hỏi bằng Y. Ví dụ: "cho đến khi bạn có đủ thông tin về khán giả và mục tiêu của tôi" hoặc "cho đến khi bạn biết tôi thích ăn gì và mục tiêu calo của tôi".)

**Ví dụ:**

*   "Tôi muốn bạn đặt câu hỏi cho tôi để giúp tôi tạo các biến thể cho tài liệu tiếp thị của mình. Bạn nên đặt câu hỏi cho đến khi bạn có đủ thông tin về các thông điệp hiện tại, khán giả và mục tiêu của tôi. Hỏi tôi câu hỏi đầu tiên."
*   "Tôi muốn bạn đặt câu hỏi cho tôi để giúp tôi chẩn đoán sự cố với Internet của mình. Hãy hỏi cho đến khi bạn có đủ thông tin để xác định hai nguyên nhân có khả năng nhất. Hỏi tôi từng câu một. Hỏi tôi câu hỏi đầu tiên."

**Lưu ý:**

Các mẫu này có thể được kết hợp và tùy chỉnh để phù hợp với nhu cầu cụ thể của bạn. Bằng cách sử dụng các mẫu này một cách sáng tạo, bạn có thể khai thác tối đa tiềm năng của LLM và tạo ra các trải nghiệm tương tác phong phú và hiệu quả.

## Few-shot Prompting là gì?

 một kỹ thuật mạnh mẽ gọi là "few-shot prompting" (gợi ý vài ví dụ) để dạy mô hình ngôn ngữ lớn (LLM) làm theo một mẫu nhất định. Ý tưởng đằng sau kỹ thuật này là cung cấp cho LLM các ví dụ về đầu vào và đầu ra mong muốn. Điều này giống như việc hướng dẫn một người học bằng cách cho họ xem các ví dụ cụ thể và giải thích kết quả mong đợi.

**Vậy "few-shot prompting" hoạt động như thế nào?**

1.  **Cung cấp các ví dụ:** Chúng ta sẽ cung cấp cho LLM một loạt các ví dụ về đầu vào và đầu ra tương ứng. Ví dụ, trong bài viết, chúng ta đã dạy mô hình phân tích cảm xúc (sentiment analysis) bằng cách đưa ra các câu đánh giá (đầu vào) và gắn nhãn cảm xúc tương ứng (đầu ra) là tích cực, tiêu cực hoặc trung lập.
2.  **Mô hình học theo mẫu:** LLM sẽ phân tích các ví dụ này và tìm ra quy luật, mẫu chung để áp dụng cho các đầu vào mới. Trong trường hợp phân tích cảm xúc, mô hình sẽ học cách xác định các từ và cụm từ mang tính tích cực, tiêu cực hoặc trung lập để đưa ra kết quả phù hợp.
3.  **Áp dụng cho đầu vào mới:** Sau khi đã học được mẫu, LLM có thể áp dụng nó cho các đầu vào mới mà nó chưa từng thấy trước đây. Ví dụ, khi đưa ra một câu đánh giá mới, mô hình sẽ phân tích và tự động xác định cảm xúc của câu đó dựa trên những gì nó đã học được từ các ví dụ trước.

**Lưu ý quan trọng khi sử dụng "few-shot prompting":**

*   **Độ chi tiết của ví dụ:** Các ví dụ cần đủ chi tiết và rõ ràng để LLM hiểu được mẫu chung. Trong ví dụ phân tích cảm xúc, nếu chỉ đưa ra các câu đánh giá ngắn gọn mà không có giải thích, mô hình có thể gặp khó khăn trong việc xác định đúng cảm xúc.
*   **Số lượng ví dụ:** Cần cung cấp đủ số lượng ví dụ để LLM có thể học được mẫu một cách hiệu quả. Tuy nhiên, không nên đưa ra quá nhiều ví dụ, vì điều này có thể làm cho mô hình bị quá tải và khó tìm ra quy luật chung.
*   **Tính đa dạng của ví dụ:** Các ví dụ nên đa dạng về nội dung và cấu trúc để LLM có thể áp dụng cho nhiều trường hợp khác nhau. Nếu chỉ đưa ra các câu đánh giá về một chủ đề cụ thể, mô hình có thể không hoạt động tốt với các chủ đề khác.

**"Few-shot prompting" - Một kỹ thuật mạnh mẽ**

Kỹ thuật này không chỉ giới hạn trong việc phân tích cảm xúc mà còn có thể được áp dụng cho nhiều tác vụ khác nhau, như tạo văn bản, dịch thuật, tóm tắt văn bản, và thậm chí cả lập kế hoạch hành động (như trong ví dụ về lái xe trong bài viết tiếng Anh). Bằng cách cung cấp các ví dụ phù hợp, chúng ta có thể "dạy" LLM thực hiện những nhiệm vụ phức tạp một cách hiệu quả.

 Bạn có thể nhớ đã được yêu cầu "trình bày cách giải" khi còn đi học, đặc biệt là trong các bài kiểm tra toán. Việc giải thích lý luận của mình không chỉ dành cho trường học; nó có giá trị trong nhiều lĩnh vực, bao gồm cả khi làm việc với các mô hình ngôn ngữ lớn (LLM). Điều thú vị là, việc nhắc nhở LLM giải thích lý luận của chúng thực sự có thể cải thiện hiệu suất của chúng.

**Tại sao điều này lại hiệu quả?**

LLM được đào tạo trên các tập dữ liệu văn bản khổng lồ và học cách dự đoán từ hoặc cụm từ tiếp theo. Nếu họ có thể giải thích chính xác lý luận của mình, điều đó làm tăng khả năng đưa ra câu trả lời đúng. Hãy coi nó như giải một câu đố: nếu thực hiện đúng các bước ban đầu, bạn sẽ dễ dàng hoàn thành toàn bộ câu đố hơn.

**Nhắc nhở Chuỗi Tư duy**

Kỹ thuật này, được gọi là "nhắc nhở chuỗi tư duy", khuyến khích LLM chia nhỏ các vấn đề thành các bước và giải thích lý luận của họ ở mỗi giai đoạn.

**Ví dụ: Câu đố về Tàu vũ trụ**

*   **Không có Chuỗi Tư duy:**
    *   **Nhắc nhở:** "Tôi đang ở trong một con tàu vũ trụ không có trọng lực. Tôi có một chiếc cốc đựng kim. Tôi di chuyển chân trên giường, làm đổ cốc xuống sàn. Tôi nhấc một cuốn sách lên và đặt nó lên bàn. Có thứ gì trên sàn không?"
    *   **Trả lời:** "Có. Khi chiếc cốc có kim bị đổ xuống sàn, cả cốc và kim sẽ rơi xuống sàn. Trong trường hợp không có trọng lực, các vật thể sẽ không rơi xuống như trên Trái đất, nhưng chúng vẫn sẽ di chuyển để đáp ứng với các lực tác dụng lên chúng."
*   **Với Chuỗi Tư duy:**
    *   **Nhắc nhở:** (Giống như trên, nhưng có thêm hướng dẫn để cung cấp lý do trước khi trả lời)
    *   **Trả lời:** "Không. Trong một con tàu vũ trụ không có trọng lực, các vật thể không hoạt động như trên Trái đất có trọng lực. Khi cốc và kim bị đổ, chúng sẽ không rơi xuống sàn... Thay vào đó, chúng sẽ nổi tại chỗ hoặc di chuyển theo hướng của lực tác dụng lên chúng. Vì vậy, trong trường hợp không có trọng lực, không có khái niệm vật thể nằm 'trên sàn' như chúng ta hiểu trên Trái đất."

Câu trả lời thứ hai, sử dụng lời nhắc chuỗi tư duy, thể hiện sự hiểu biết sâu sắc hơn về tình huống và câu trả lời chính xác hơn.

**Khi nào nên sử dụng Nhắc nhở Chuỗi Tư duy**

Nhắc nhở chuỗi tư duy đặc biệt hữu ích khi xử lý các tác vụ yêu cầu lý luận hoặc tính toán phức tạp. Bằng cách chia nhỏ vấn đề và giải thích từng bước, bạn hướng dẫn LLM đưa ra giải pháp chính xác hơn.

 Sự phát triển nhanh chóng của các mô hình ngôn ngữ lớn (LLM) đặt ra thách thức trong việc duy trì hiệu quả của các lời nhắc (prompt). Với sự xuất hiện của các mô hình mới như ChatGPT, GPT-4, LLaMA, Alpaca và Vicuna, các lời nhắc được thiết kế cẩn thận của chúng ta có thể trở nên lỗi thời hoặc kém hiệu quả do những thay đổi trong kiến trúc mô hình hoặc dữ liệu được xử lý.

Để giải quyết vấn đề này, chúng ta cần các phương pháp đáng tin cậy để đánh giá kết quả của lời nhắc và đảm bảo chất lượng của nó theo thời gian. Mặc dù đánh giá của con người là rất có giá trị, chúng ta cũng tìm kiếm các giải pháp tự động có thể mở rộng.

Điều thú vị là, bản thân LLM có thể được tận dụng để tự đánh giá. Chúng ta có thể sử dụng một LLM để chấm điểm kết quả của một LLM khác hoặc thậm chí chính nó. Cách tiếp cận này phản ánh cách LLM đã được sử dụng để dạy lẫn nhau.

**Ví dụ:**

Hãy hướng dẫn ChatGPT chấm điểm kết quả của một lời nhắc trích xuất các sự kiện và ngày tháng từ một mục nhập Wikipedia về Đại học Vanderbilt:

1.  **Đầu vào:** Văn bản về Đại học Vanderbilt đề cập đến việc thành lập trường vào năm 1873.
2.  **Đầu ra:** "Sau đây là danh sách các sự kiện và ngày tháng: Vanderbilt thành lập năm 1873."
3.  **Giải thích:** Văn bản không mong muốn ở đầu; chỉ cần tên và ngày tháng.
4.  **Điểm:** 5/10

Bằng cách cung cấp một vài ví dụ được chấm điểm như thế này, ChatGPT học cách đánh giá xem kết quả đầu ra có phù hợp với định dạng mong muốn (tên sự kiện, dấu phẩy, ngày tháng) hay không.

Cách tiếp cận đánh giá này mang lại một số lợi ích:

*   **Kiểm soát chất lượng tự động:** LLM có thể tự động kiểm tra kết quả đầu ra của các LLM khác hoặc chính nó, đảm bảo tính nhất quán và tuân thủ các định dạng mong muốn.
*   **Khả năng mở rộng:** Đánh giá tự động cho phép phân tích quy mô lớn kết quả đầu ra của lời nhắc, tiết kiệm thời gian và tài nguyên.
*   **Tính linh hoạt:** Các lời nhắc đánh giá có thể được điều chỉnh cho các tác vụ và tiêu chí chấm điểm cụ thể, cho phép kiểm soát chất lượng một cách linh hoạt.

**Lưu ý:**

*   Mặc dù cách tiếp cận này rất hứa hẹn, nhưng điều quan trọng là phải tạo ra các tiêu chí chấm điểm toàn diện và rõ ràng.
*   Đánh giá của con người vẫn rất quan trọng, đặc biệt là đối với các tác vụ phức tạp hoặc tinh tế.

 **Mẫu Trò Chơi**

Một trong những cách thú vị nhất để học một chủ đề hoặc kỹ năng mới là thông qua trò chơi. Trò chơi vừa vui vừa mang tính thử thách, và "Mẫu Trò Chơi" cho phép bạn khai thác sức mạnh của AI (như ChatGPT) để tạo và hướng dẫn các trò chơi phù hợp với mục tiêu học tập của bạn.

**Cách Hoạt Động:**

1.  **Người Điều Khiển Trò Chơi:** Bạn yêu cầu AI trở thành người điều khiển trò chơi – nó sẽ đặt ra các quy tắc và điều khiển trò chơi.
2.  **Chủ Đề và Các Quy Tắc Cơ Bản:** Bạn cung cấp một chủ đề (ví dụ: toán học, lịch sử) và bất kỳ quy tắc cơ bản nào bạn muốn (ví dụ: câu hỏi trắc nghiệm, giới hạn thời gian).
3.  **Nội Dung Do AI Tạo:** AI sử dụng cơ sở kiến thức rộng lớn của mình để điền vào phần còn lại, tạo câu hỏi, thử thách hoặc tình huống.

**Lợi Ích:**

*   **Học Tập Hấp Dẫn:** Trò chơi giúp việc học trở nên vui vẻ và tương tác hơn.
*   **Tùy Chỉnh:** Bạn kiểm soát chủ đề và cấu trúc cơ bản, đảm bảo trò chơi phù hợp với sở thích và mục tiêu học tập của bạn.
*   **Tạo Nội Dung:** Dữ liệu huấn luyện khổng lồ của AI cho phép nó tạo ra nội dung phong phú và đa dạng, giúp bạn tiết kiệm công sức tự nghĩ ra mọi thứ.

**Ví dụ: Trò Chơi Kỹ Thuật Đề Xuất (Prompt Engineering)**

Bạn có thể yêu cầu AI tạo một trò chơi để cải thiện kỹ năng kỹ thuật đề xuất của bạn. AI có thể:

*   Tạo các nhiệm vụ yêu cầu các loại đề xuất khác nhau (ví dụ: viết một đề xuất để tóm tắt văn bản, tạo ý tưởng sáng tạo).
*   Đánh giá các đề xuất của bạn và cung cấp phản hồi.
*   Tăng độ khó khi bạn tiến bộ.

**Mẫu Khuôn Mẫu**

Đôi khi, việc nhận kết quả đầu ra của AI theo đúng định dạng bạn cần có thể khó khăn. "Mẫu Khuôn Mẫu" giải quyết vấn đề này bằng cách cho phép bạn cung cấp một khuôn mẫu mà AI phải điền vào.

**Cách Hoạt Động:**

1.  **Xác Định Các Trình Giữ Chỗ:** Các từ viết hoa hoặc ký tự đặc biệt (ví dụ: \) cho biết nơi AI nên chèn nội dung.
2.  **Cung Cấp Hướng Dẫn:** Giải thích mục đích của từng trình giữ chỗ (ví dụ: "TÊN" cho tên của một người, "TÓM TẮT" cho phần tóm tắt một câu).
3.  **Đưa Ra Khuôn Mẫu:** Cho AI thấy định dạng chính xác mà bạn muốn.

**Ví dụ:**

Khuôn Mẫu: # TÊN ## Tóm Tắt Sơ Lược MỘT CÂU TÓM TẮT ## Mô Tả Chi Tiết MỘT ĐOẠN TÓM TẮT

Sau đó, bạn có thể dán vào một tiểu sử, và AI sẽ tạo một hồ sơ có cấu trúc cho mỗi người được đề cập, theo khuôn mẫu của bạn.

**Lợi Ích:**

*   **Định Dạng Chính Xác:** Đảm bảo kết quả đầu ra phù hợp với yêu cầu của bạn.
*   **Hướng Dẫn Phức Tạp:** Các trình giữ chỗ có thể chứa các hướng dẫn chi tiết, cho phép kết quả đầu ra sắc thái và tinh vi.
*   **Tiết Kiệm Thời Gian:** Tự động hóa quá trình định dạng, giúp bạn tiết kiệm công sức.

**Ghi Nhớ:** Cả hai mẫu đều là công cụ mạnh mẽ. Hãy thử nghiệm, vui vẻ và điều chỉnh chúng theo nhu cầu cụ thể của bạn!

## Khó lý giải

 Việc giao tiếp với các mô hình ngôn ngữ lớn (LLM) không phải lúc nào cũng cần diễn đạt bằng câu đầy đủ. Trong thực tế, chúng ta thường sử dụng các ngôn ngữ chuyên biệt hoặc cách viết tắt để tăng hiệu quả. Hãy nghĩ đến các nhà toán học, người ghi chú, hoặc thậm chí các nhân viên ứng phó khẩn cấp sử dụng mã để giao tiếp nhanh chóng. Những ngôn ngữ chuyên biệt này cho phép trao đổi thông tin ngắn gọn và chính xác, nhưng chỉ khi cả hai bên hiểu ý nghĩa.

Điều này đưa chúng ta đến "Mô hình Tạo Ngôn ngữ Meta" - một cách để dạy LLM một ngôn ngữ mới hoặc cách viết tắt để tương tác được sắp xếp hợp lý hơn. Đây là cách thức hoạt động:

1.  **Định nghĩa Ngôn ngữ:** Giải thích cho LLM các ký hiệu, thuật ngữ hoặc câu lệnh của ngôn ngữ viết tắt của bạn và ý nghĩa tương ứng của chúng.
2.  **Minh họa bằng Ví dụ:** Cung cấp các ví dụ về cách viết tắt của bạn được dịch thành câu đầy đủ, tương tự như cung cấp các ví dụ "few-shot".
3.  **Trò chuyện:** Bắt đầu sử dụng ngôn ngữ viết tắt của bạn và LLM sẽ hiểu và phản hồi cho phù hợp.

**Ví dụ Minh họa: Ứng dụng Lập kế hoạch Chuyến đi**

Hãy tưởng tượng việc tạo một ứng dụng lập kế hoạch chuyến đi với LLM. Thay vì viết ra các câu đầy đủ, bạn có thể tạo một cách viết tắt như sau:

*   Nashville, 3 -> Memphis, 2 có nghĩa là "Lộ trình của tôi đi từ Nashville đến Memphis, ở lại Nashville 3 ngày và Memphis 2 ngày."

Bằng cách dạy cho LLM cách viết tắt này, giờ đây bạn có thể cung cấp hành trình của mình một cách ngắn gọn hơn nhiều. Ví dụ:

*   Nashville, 0 -> Dallas, 1 -> Granbury, Texas, 4

LLM sẽ hiểu đây là một chuyến đi bắt đầu từ Nashville (không ở lại), sau đó đến Dallas trong một ngày, và cuối cùng là đến Granbury, Texas trong bốn ngày. Sau đó, nó có thể tạo các hành trình cho phù hợp. Let me know if you'd like any further adjustments or have more text to optimize and translate!

## Mẫu Công Thức (Recipe Pattern)
 Đôi khi, khi làm việc với một mô hình ngôn ngữ lớn (LLM), chúng ta biết một phần giải pháp cho một vấn đề. Chúng ta có thể có một số bước hoặc thông tin, nhưng chúng ta cần LLM điền vào chỗ trống, hoàn thành "công thức" cho chúng ta. Đây là lúc mẫu công thức phát huy tác dụng.

**Cách Hoạt Động**

1.  **Mục tiêu:** Cho LLM biết mục tiêu bạn muốn đạt được.
2.  **Các Bước Một Phần:** Cung cấp các phần của giải pháp mà bạn đã biết.
3.  **Điền Vào Chỗ Trống:** Yêu cầu LLM hoàn thành các bước còn thiếu.

Mẫu này giúp thu hẹp khoảng trống kiến thức và tạo ra một giải pháp hoàn chỉnh. Điều thú vị là, cách trực quan của chúng ta để mô tả những khoảng trống này – sử dụng dấu chấm lửng (...) hoặc các ký hiệu giữ chỗ tương tự – là điều mà các LLM như ChatGPT có thể hiểu được.

**Ví dụ: Lập Kế Hoạch Chuyến Đi**

Hãy tưởng tượng bạn đang xây dựng một ứng dụng lập kế hoạch chuyến đi. Bạn nói với LLM:

"Tôi sẽ cho bạn biết điểm bắt đầu và điểm kết thúc của tôi, và bạn sẽ cung cấp một danh sách đầy đủ các điểm dừng, bao gồm cả những nơi dừng chân giữa chừng."

Đây là một công thức chưa hoàn chỉnh. Bạn cung cấp điểm bắt đầu (ví dụ: Nashville) và điểm kết thúc (ví dụ: Fairhope, Alabama), nhưng cần LLM điền vào các điểm dừng ở giữa.

Bạn thậm chí có thể sử dụng một cách viết tắt như thế này:

"Nashville, 0 -> ... -> ... -> Fairhope, Alabama 2"

Điều này cho biết bạn muốn có hai điểm dừng giữa Nashville và Fairhope, và LLM sẽ đề xuất những địa điểm phù hợp (ví dụ: Birmingham và Montgomery).

**Một Ví dụ Khác: Động Não**

Mẫu công thức cũng có thể được sử dụng để động não. Giả sử bạn muốn ChatGPT viết các lời nhắc để phân biệt năm nhuận:

"Viết một số lời nhắc cho chính bạn để xác định xem một ngày ở định dạng năm, tháng, ngày có phải là năm nhuận hay không. Kết quả đầu ra phải là 'Năm là năm nhuận' hoặc 'Đây không phải là năm nhuận'."

ChatGPT sẽ tạo ra các lời nhắc thay thế, mỗi lời nhắc có một cách tiếp cận khác nhau để giải quyết nhiệm vụ.

**Điểm Chính**

*   **Linh hoạt:** Mẫu công thức có thể thích ứng với các nhiệm vụ khác nhau, từ lập kế hoạch chuyến đi đến kỹ thuật nhắc nhở.
*   **Hợp tác giữa Con người và AI:** Nó tận dụng kiến thức và khả năng của LLM để tăng cường khả năng của riêng bạn.
*   **Tinh chỉnh lặp đi lặp lại:** Bạn có thể tinh chỉnh "công thức" được tạo ra thông qua phản hồi và tương tác thêm với LLM.

